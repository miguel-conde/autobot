{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "from utils.tools import tool_current_weather, get_current_weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "        tool_current_weather,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's the weather like today\"})\n",
    "\n",
    "chat_response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    messages = messages, \n",
    "    tools = tools, tool_choice=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-8PtKpFNFIVDYXoeMMSeQEp5CVW27z',\n",
       " 'choices': [Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=\"Sure, I can help you with that. Could you please provide me with the location for which you'd like to know the current weather?\", role='assistant', function_call=None, tool_calls=None))],\n",
       " 'created': 1701181599,\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': 'fp_eeff13170a',\n",
       " 'usage': CompletionUsage(completion_tokens=28, prompt_tokens=103, total_tokens=131)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finish_reason': 'tool_calls',\n",
       " 'index': 0,\n",
       " 'message': ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_mFIjSPsCskjjmpZsiETZZDzm', function=Function(arguments='{\"location\":\"San Francisco, CA\",\"unit\":\"celsius\"}', name='get_current_weather'), type='function')])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.choices[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': [ChatCompletionMessageToolCall(id='call_mFIjSPsCskjjmpZsiETZZDzm', function=Function(arguments='{\"location\":\"San Francisco, CA\",\"unit\":\"celsius\"}', name='get_current_weather'), type='function')]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.choices[0].message.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 42, 'prompt_tokens': 39, 'total_tokens': 81}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.usage.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = []\n",
    "messages.append({\"role\": \"user\", \"content\": \"I'm in Glasgow, Scotland.\"})\n",
    "\n",
    "chat_response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    messages = messages, \n",
    "    tools=tools, tool_choice    = \"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: chatcmpl-8PtLSnqMJuny3IlI2XaaBiEdDeWM7\n",
      "choices: [Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=\"Got it! I'll get the current weather for Glasgow, Scotland.\", role='assistant', function_call=None, tool_calls=None))]\n",
      "created: 1701181638\n",
      "model: gpt-3.5-turbo-1106\n",
      "object: chat.completion\n",
      "system_fingerprint: fp_eeff13170a\n",
      "usage: CompletionUsage(completion_tokens=14, prompt_tokens=82, total_tokens=96)\n"
     ]
    }
   ],
   "source": [
    "for key, value in chat_response.__dict__.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finish_reason': 'tool_calls',\n",
       " 'index': 0,\n",
       " 'message': ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ry7lQnitwp7Pfx4Gk5eNJdk7', function=Function(arguments='{\"location\":\"Glasgow, Scotland\"}', name='get_current_weather'), type='function')])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.choices[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': [ChatCompletionMessageToolCall(id='call_ry7lQnitwp7Pfx4Gk5eNJdk7', function=Function(arguments='{\"location\":\"Glasgow, Scotland\"}', name='get_current_weather'), type='function')]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.choices[0].message.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'call_ry7lQnitwp7Pfx4Gk5eNJdk7',\n",
       " 'function': Function(arguments='{\"location\":\"Glasgow, Scotland\"}', name='get_current_weather'),\n",
       " 'type': 'function'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.choices[0].message.tool_calls[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"I'm in Glasgow, Scotland.\"})\n",
    "chat_response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    messages = messages, \n",
    "    tools=tools\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8PrPWucfA60Gm605y0oxzPEHZGvoX', choices=[Choice(finish_reason='tool_calls', index=0, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_4RAdhAQNDcdgywJNr8zVBpLN', function=Function(arguments='{\"location\":\"Glasgow, Scotland\"}', name='get_current_weather'), type='function')]))], created=1701174202, model='gpt-3.5-turbo-1106', object='chat.completion', system_fingerprint='fp_eeff13170a', usage=CompletionUsage(completion_tokens=19, prompt_tokens=113, total_tokens=132))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mcondedesimon\\Documents\\PLAYGROUND\\auto_mmm\\PYTHON\\notebooks\\notas.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mcondedesimon/Documents/PLAYGROUND/auto_mmm/PYTHON/notebooks/notas.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m inspect\u001b[39m.\u001b[39;49mgetmembers(utils)[\u001b[39m9\u001b[39;49m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "inspect.getmembers(utils)[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ArrowDtype',\n",
       " 'BooleanDtype',\n",
       " 'Categorical',\n",
       " 'CategoricalDtype',\n",
       " 'CategoricalIndex',\n",
       " 'DataFrame',\n",
       " 'DateOffset',\n",
       " 'DatetimeIndex',\n",
       " 'DatetimeTZDtype',\n",
       " 'ExcelFile',\n",
       " 'ExcelWriter',\n",
       " 'Flags',\n",
       " 'Float32Dtype',\n",
       " 'Float64Dtype',\n",
       " 'Grouper',\n",
       " 'HDFStore',\n",
       " 'Index',\n",
       " 'IndexSlice',\n",
       " 'Int16Dtype',\n",
       " 'Int32Dtype',\n",
       " 'Int64Dtype',\n",
       " 'Int8Dtype',\n",
       " 'Interval',\n",
       " 'IntervalDtype',\n",
       " 'IntervalIndex',\n",
       " 'MultiIndex',\n",
       " 'NA',\n",
       " 'NaT',\n",
       " 'NamedAgg',\n",
       " 'Period',\n",
       " 'PeriodDtype',\n",
       " 'PeriodIndex',\n",
       " 'RangeIndex',\n",
       " 'Series',\n",
       " 'SparseDtype',\n",
       " 'StringDtype',\n",
       " 'Timedelta',\n",
       " 'TimedeltaIndex',\n",
       " 'Timestamp',\n",
       " 'UInt16Dtype',\n",
       " 'UInt32Dtype',\n",
       " 'UInt64Dtype',\n",
       " 'UInt8Dtype',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__docformat__',\n",
       " '__file__',\n",
       " '__git_version__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_built_with_meson',\n",
       " '_config',\n",
       " '_is_numpy_dev',\n",
       " '_libs',\n",
       " '_pandas_datetime_CAPI',\n",
       " '_pandas_parser_CAPI',\n",
       " '_testing',\n",
       " '_typing',\n",
       " '_version_meson',\n",
       " 'annotations',\n",
       " 'api',\n",
       " 'array',\n",
       " 'arrays',\n",
       " 'bdate_range',\n",
       " 'compat',\n",
       " 'concat',\n",
       " 'core',\n",
       " 'crosstab',\n",
       " 'cut',\n",
       " 'date_range',\n",
       " 'describe_option',\n",
       " 'errors',\n",
       " 'eval',\n",
       " 'factorize',\n",
       " 'from_dummies',\n",
       " 'get_dummies',\n",
       " 'get_option',\n",
       " 'infer_freq',\n",
       " 'interval_range',\n",
       " 'io',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'json_normalize',\n",
       " 'lreshape',\n",
       " 'melt',\n",
       " 'merge',\n",
       " 'merge_asof',\n",
       " 'merge_ordered',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'offsets',\n",
       " 'option_context',\n",
       " 'options',\n",
       " 'pandas',\n",
       " 'period_range',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plotting',\n",
       " 'qcut',\n",
       " 'read_clipboard',\n",
       " 'read_csv',\n",
       " 'read_excel',\n",
       " 'read_feather',\n",
       " 'read_fwf',\n",
       " 'read_gbq',\n",
       " 'read_hdf',\n",
       " 'read_html',\n",
       " 'read_json',\n",
       " 'read_orc',\n",
       " 'read_parquet',\n",
       " 'read_pickle',\n",
       " 'read_sas',\n",
       " 'read_spss',\n",
       " 'read_sql',\n",
       " 'read_sql_query',\n",
       " 'read_sql_table',\n",
       " 'read_stata',\n",
       " 'read_table',\n",
       " 'read_xml',\n",
       " 'reset_option',\n",
       " 'set_eng_float_format',\n",
       " 'set_option',\n",
       " 'show_versions',\n",
       " 'test',\n",
       " 'testing',\n",
       " 'timedelta_range',\n",
       " 'to_datetime',\n",
       " 'to_numeric',\n",
       " 'to_pickle',\n",
       " 'to_timedelta',\n",
       " 'tseries',\n",
       " 'unique',\n",
       " 'util',\n",
       " 'value_counts',\n",
       " 'wide_to_long']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['calculate_geom_ad_stock']\n"
     ]
    }
   ],
   "source": [
    "funciones = [func for func in dir(mmm) if callable(getattr(mmm, func))]\n",
    "print(funciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Calcula el 'ad stock' geométrico de una serie de datos aplicando un factor de decaimiento.\n",
      "\n",
      "    El 'ad stock' es un concepto en marketing y economía que representa el impacto acumulado\n",
      "    de la publicidad a lo largo del tiempo. Esta función aplica un modelo de ad stock geométrico,\n",
      "    donde el efecto de la publicidad se deprecia de forma geométrica en cada período.\n",
      "\n",
      "    Args:\n",
      "        series (List[float]): Lista de valores que representan la inversión o impacto publicitario en cada período.\n",
      "        decay_factor (float): Factor de decaimiento que se aplica a la acumulación de ad stock. \n",
      "                              Si es mayor que 1, se considera como porcentaje y se divide por 100.\n",
      "        initial_value (float, optional): Valor inicial de ad stock. Por defecto es 0.\n",
      "\n",
      "    Returns:\n",
      "        List[float]: Lista de valores actualizados representando el ad stock acumulado.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "doc = mmm.calculate_geom_ad_stock.__doc__\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVERSACIÓN INTERESANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "(.venv) C:\\Users\\mcondedesimon\\Documents\\PLAYGROUND\\auto_mmm>c:/Users/mcondedesimon/Documents/PLAYGROUND/auto_mmm/.venv/Scripts/python.exe -m IPython --no-autoindent c:/Users/mcondedesimon/Documents/PLAYGROUND/auto_mmm/PYTHON/tests/test_chatbot.py\n",
    "Using gpt-3.5-turbo\n",
    "Usuario: importa el modulo 'mmm'\n",
    "CODE:\n",
    "\n",
    " import mmm\n",
    "\n",
    "res = \"El módulo 'mmm' ha sido importado correctamente.\"\n",
    "res = El módulo 'mmm' ha sido importado correctamente.\n",
    "Chatbot: El módulo 'mmm' ha sido importado correctamente.\n",
    "Usuario: carga el fichero \".data/clean/mtcars.csv\"\n",
    "Chatbot: Para cargar el archivo \".data/clean/mtcars.csv\", necesitamos utilizar el módulo `pandas`. A continuación, generaremos el código necesario para cargar el archivo y asignaremos el resultado a la variable `res`.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo\n",
    "df = pd.read_csv('.data/clean/mtcars.csv')\n",
    "\n",
    "# Generar el texto necesario para la interacción con el usuario\n",
    "res = \"El archivo '.data/clean/mtcars.csv' ha sido cargado correctamente.\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Por favor, ejecuta el código proporcionado para cargar el archivo.\n",
    "Usuario: carga el fichero \".data/clean/mtcars.csv\" en un dataframe pandas\n",
    "CODE:\n",
    "\n",
    " import pandas as pd\n",
    "\n",
    "# Cargar el archivo\n",
    "df = pd.read_csv('.data/clean/mtcars.csv')\n",
    "\n",
    "# Generar el texto necesario para la interacción con el usuario\n",
    "res = \"El archivo '.data/clean/mtcars.csv' ha sido cargado correctamente.\"\n",
    "Chatbot: Lo siento, parece que el archivo '.data/clean/mtcars.csv' no se encuentra en el directorio actual. Asegúrate de que el archivo existe y de que la ruta proporcionada es correcta.\n",
    "Usuario: carga el fichero \"./data/clean/mtcars.csv\" en un dataframe pandas \n",
    "CODE:\n",
    "\n",
    " import pandas as pd\n",
    "\n",
    "# Cargar el archivo\n",
    "df = pd.read_csv('./data/clean/mtcars.csv')\n",
    "\n",
    "# Generar el texto necesario para la interacción con el usuario\n",
    "res = \"El archivo './data/clean/mtcars.csv' ha sido cargado correctamente.\"\n",
    "res = El archivo './data/clean/mtcars.csv' ha sido cargado correctamente.\n",
    "Chatbot: El archivo './data/clean/mtcars.csv' ha sido cargado correctamente.\n",
    "Usuario: que funciones hay en el modulo 'mmm'?\n",
    "CODE:\n",
    "\n",
    " import mmm\n",
    "\n",
    "# Obtener las funciones del módulo 'mmm'\n",
    "funciones = [func for func in dir(mmm) if callable(getattr(mmm, func))]\n",
    "\n",
    "# Generar el texto necesario para la interacción con el usuario\n",
    "res = f'Las funciones disponibles en el módulo mmm son: {funciones}'\n",
    "res = Las funciones disponibles en el módulo mmm son: ['calculate_geom_ad_stock']\n",
    "Chatbot: Las funciones disponibles en el módulo 'mmm' son: ['calculate_geom_ad_stock']\n",
    "Usuario: Qué hace la función 'calculate_geom_ad_stock' de la libreria 'mmm'?\n",
    "CODE:\n",
    "\n",
    " import mmm\n",
    "\n",
    "# Obtener la documentación de la función 'calculate_geom_ad_stock'\n",
    "doc = mmm.calculate_geom_ad_stock.__doc__\n",
    "\n",
    "# Generar el texto necesario para la interacción con el usuario\n",
    "res = f'La función calculate_geom_ad_stock de la librería mmm realiza lo siguiente:\n",
    "\n",
    "{doc}'\n",
    "Chatbot: La función 'calculate_geom_ad_stock' de la librería 'mmm' calcula el stock geométrico ajustado. Lamentablemente, no se proporciona más información sobre cómo se realiza este cálculo.\n",
    "Usuario: que argumentos hay que pasar a la función 'calculate_geom_ad_stock'?\n",
    "CODE:\n",
    "\n",
    " import inspect\n",
    "import mmm\n",
    "\n",
    "# Obtener la información de los argumentos de la función 'calculate_geom_ad_stock'\n",
    "args = inspect.getfullargspec(mmm.calculate_geom_ad_stock)\n",
    "\n",
    "# Generar el texto necesario para la interacción con el usuario\n",
    "res = f'Los argumentos de la función calculate_geom_ad_stock son: {args.args}'\n",
    "res = Los argumentos de la función calculate_geom_ad_stock son: ['series', 'decay_factor', 'initial_value']\n",
    "Chatbot: Los argumentos de la función 'calculate_geom_ad_stock' son: 'series', 'decay_factor' y 'initial_value'.\n",
    "Usuario: muestrame las 5 primeras filas del dataframe con los datos del fichero mtcars\n",
    "CODE:\n",
    "\n",
    " df.head(5)\n",
    "Chatbot: Mis disculpas, olvidé asignar el resultado a la variable 'res'. Aquí tienes el código corregido:\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# Mostrar las 5 primeras filas del dataframe\n",
    "res = df.head(5).to_string(index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "Por favor, ejecuta el código proporcionado para mostrar las 5 primeras filas del dataframe con los datos del archivo mtcars.\n",
    "Usuario: Intentalo de nuevo\n",
    "CODE:\n",
    "\n",
    " res = df.head(5).to_string(index=False)\n",
    "res =  mpg  cyl  disp  hp  drat    wt  qsec  vs  am  gear  carb\n",
    "21.0    6 160.0 110  3.90 2.620 16.46   0   1     4     4\n",
    "21.0    6 160.0 110  3.90 2.875 17.02   0   1     4     4\n",
    "22.8    4 108.0  93  3.85 2.320 18.61   1   1     4     1\n",
    "21.4    6 258.0 110  3.08 3.215 19.44   1   0     3     1\n",
    "18.7    8 360.0 175  3.15 3.440 17.02   0   0     3     2\n",
    "Chatbot: Aquí tienes las 5 primeras filas del dataframe con los datos del archivo mtcars:\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
    "0  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
    "1  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
    "2  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
    "3  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
    "4  18.7    8  360.0  175  3.15  3.440\n",
    "Usuario: añade una columna a este datframe resultado de aplicar el adstock a la columna mpg. Usa un decay_factor = 0.1\n",
    "CODE:\n",
    "\n",
    " df['adstock_mpg'] = mmm.calculate_geom_ad_stock(df['mpg'], decay_factor=0.1)\n",
    "\n",
    "# Generar el texto necesario para la interacción con el usuario\n",
    "res = 'Se ha añadido la columna adstock_mpg al dataframe.'\n",
    "res = Se ha añadido la columna adstock_mpg al dataframe.\n",
    "Chatbot: Se ha añadido la columna 'adstock_mpg' al dataframe.\n",
    "Usuario: muestrame las 5 primeras filas de las columnas mpg y adstock_mpg\n",
    "CODE:\n",
    "\n",
    " res = df[['mpg', 'adstock_mpg']].head(5).to_string(index=False)\n",
    "res =  mpg  adstock_mpg\n",
    "21.0      21.0000\n",
    "21.0      23.1000\n",
    "22.8      25.1100\n",
    "21.4      23.9110\n",
    "18.7      21.0911\n",
    "Chatbot: Aquí tienes las 5 primeras filas de las columnas 'mpg' y 'adstock_mpg':\n",
    "```\n",
    "\n",
    "```\n",
    "   mpg  adstock_mpg\n",
    "0  21.0      21.0000\n",
    "1  21.0      23.1000\n",
    "2  22.8      25.1100\n",
    "3  21.4      23.9110\n",
    "4  18.7      21.0911\n",
    "```\n",
    "\n",
    "```\n",
    "Estas son las primeras 5 filas de las columnas 'mpg' y 'adstock_mpg' después de aplicar el adstock a la columna 'mpg'.\n",
    "Usuario:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea de Arquitectura\n",
    "\n",
    "Quiero hacer una aplicación que genere código python, lo ejecute en local y asi ayude a hacer análisis y modelado en MMM.\n",
    "He pensado la siguiente arquitectura:\n",
    "- Crear un chatbot con el API de openai \n",
    "- Este chatbot tiene acceso a un CodeInterpreter local, al que accede como una funcion openai\n",
    "- EL Codeinterpreter tiene acceso a un entorno de ejecución en memoria, de manera que lo que se ejecuta o carga es persistente entre las interacciones del chatbot.\n",
    "- El código que genera devuelve al final un texto que el LLM puede entender\n",
    "- Existe una libreria python local que contiene código específico del dominio MMM, de manera que el chatbot puede usarla\n",
    "- Esta libreria tiene su documentación en ficheros pdf o html. El sistema carga la  documentación en un vectorstore o similar (retriever), de manera que puede usarlo para saber que métodos de esta libreria puede usar en cada momento.\n",
    "- Se usa una interfaz streamlite o gradio para interactuar con el chatbot\n",
    "- Sería bueno que se registrasen (logs) las sesiones con el chatbot\n",
    "- Ademas el chatbot tiene acceso a internet, así que puede hacer búsquedas sobre MMM o sobre el sector de negocio con el que se esté trabajando, etc.\n",
    "\n",
    "\n",
    "Quizá se pueda hacer con un assistant, que aceta tools (el codeinterpreter) y retrieval (para la documentación de la libreria)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
